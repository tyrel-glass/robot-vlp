{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-29 10:43:12.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrobot_vlp.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/tyrelglass/PhD/Repositories/robot-vlp\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/3mr_0p157c9d4qgnmrzwc8nm0000gn/T/ipykernel_65161/2091869221.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperParameters\n"
     ]
    }
   ],
   "source": [
    "from robot_vlp.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR, FIGURES_DIR, MODELS_DIR, EXPERIMENT_DATA_DIR\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "import robot_vlp.data.preprocessing as p\n",
    "import matplotlib.pyplot as plt\n",
    "import robot_vlp.data_collection.communication as c\n",
    "import pandas as pd\n",
    "from kerastuner import HyperParameters\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, BatchNormalization, LayerNormalization, Input, Bidirectional, Attention, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import kerastuner as kt\n",
    "import json\n",
    "\n",
    "import robot_vlp.modeling.gen_cnc_vlp_model as vlp\n",
    "\n",
    "import robot_vlp.data_collection.experment_processing as ep\n",
    "\n",
    "# import robot_vlp.data.odometer_path_navigation as pg\n",
    "# import robot_vlp.plots.model_performance_plotting as pp\n",
    "import robot_vlp.modeling.rnn as rnn\n",
    "import robot_vlp.stats.navigation_performance as nav\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "\n",
    "from robot_vlp.modeling.rnn_config import GLOBAL_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlp_models = vlp.load_vlp_models()\n",
    "vlp_model = vlp_models['high_acc']\n",
    "# df_lst = []\n",
    "# for i in range(10):\n",
    "#     path = EXPERIMENT_DATA_DIR/f'Robot/exp1_{i}.csv'\n",
    "#     df_lst.append(ep.process_robot_exp_file(path, vlp_model))\n",
    "\n",
    "df_lst = []\n",
    "for i in range(10):\n",
    "    test_file = INTERIM_DATA_DIR / 'exp_vive_navigated_paths'/f'exp1_{i}_high_acc.csv'\n",
    "    df = pd.read_csv(test_file)\n",
    "    df_lst.append(df)\n",
    "\n",
    "train_files = df_lst[:-2]\n",
    "valid_files = df_lst[-2:-1]\n",
    "test_files = df_lst[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robot_vlp.modeling.rnn as rnn\n",
    "\n",
    "\n",
    "def expand(y):\n",
    "    y_rad = y[:,2] \n",
    "    y_angles = np.column_stack((np.sin(y_rad), np.cos(y_rad)))\n",
    "    return [y[:,:2], y_angles]\n",
    "\n",
    "# Define a cosine similarity–based loss function for headings\n",
    "def cosine_loss(y_true, y_pred):\n",
    "    # Use tf.keras.losses.CosineSimilarity which returns negative values (max similarity = -1)\n",
    "    cos_sim = tf.keras.losses.CosineSimilarity(axis=1)(y_true, y_pred)\n",
    "    # Convert to a loss (0 when identical, higher when misaligned)\n",
    "    return 1 + cos_sim  # When vectors are identical, cos_sim = -1, so loss becomes 0\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    X = df[['vlp_x_hist', 'vlp_y_hist','vlp_heading_hist_rad','vlp_heading_change_rad', 'encoder_heading_change_rad', 'encoder_heading_hist_rad', 'encoder_x_hist','encoder_y_hist']].values\n",
    "    y = df[['x_hist', 'y_hist','heading_hist_rad']].values\n",
    "    X_win, y_win, m_win = p.window_data(X, y, y, overlap = 0.999999, window_len = 25)\n",
    "    return X_win, y_win, m_win\n",
    "\n",
    "\n",
    "def read_csv_to_train(file_list):\n",
    "    X_lst = []\n",
    "    y_lst = []\n",
    "    m_lst = []\n",
    "\n",
    "    for df in file_list:\n",
    "        X_win, y_win, m_win = preprocess_df(df)\n",
    "        X_lst.append(X_win)\n",
    "        y_lst.append(y_win)\n",
    "        m_lst.append(m_win)\n",
    "\n",
    "\n",
    "    X = np.concatenate(X_lst, axis = 0)\n",
    "    y = np.concatenate(y_lst, axis = 0)\n",
    "    m = np.concatenate(m_lst, axis = 0)\n",
    "\n",
    "    return X, y, m\n",
    "\n",
    "X_train, y_train, _ = read_csv_to_train(train_files)\n",
    "X_valid, y_valid, _ = read_csv_to_train(valid_files)\n",
    "X_test, y_test, _ = read_csv_to_train(test_files)\n",
    "\n",
    "X_train = np.nan_to_num(X_train, nan = 0)\n",
    "X_valid = np.nan_to_num(X_valid, nan = 0)\n",
    "X_test = np.nan_to_num(X_test, nan = 0)\n",
    "\n",
    "# after you've built `X_train` with shape (N, window, 8):\n",
    "flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "rnn.global_norm.adapt(flat)\n",
    "\n",
    "# 2) grab its statistics and push them into your module globals\n",
    "rnn.FEAT_MEAN = rnn.global_norm.mean.numpy()\n",
    "rnn.FEAT_VAR  = rnn.global_norm.variance.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 parameter tuning - neurons and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 01m 57s]\n",
      "val_loss: 0.006200662348419428\n",
      "\n",
      "Best val_loss So Far: 0.0042019798420369625\n",
      "Total elapsed time: 1d 02h 58m 51s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    rnn.build_architecture_model,   # ← use your config‑driven builder\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=200,\n",
    "    directory=\"rnn_tuning\",\n",
    "    project_name=\"rnn_random_search\",\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    \"logs/random_search\", histogram_freq=1\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    expand(y_train),\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        ),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyrelglass/miniforge3/envs/robot-vlp/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GLOBAL_CONFIG updated: {'num_layers': 2, 'recurrent_units': [32, 8]}\n"
     ]
    }
   ],
   "source": [
    "# Extract the top 10 trials from your tuner\n",
    "best_trials = tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "rows = []\n",
    "for trial in best_trials:\n",
    "    hp = trial.hyperparameters\n",
    "    # Pull out architecture hyperparameters\n",
    "    num_layers = hp.get('num_layers')\n",
    "    rec_units = [hp.get(f'recurrent_units_{i}') for i in range(num_layers)]\n",
    "    # Pad to a fixed width (max 4 layers)\n",
    "    rec_units += [None] * (4 - len(rec_units))\n",
    "    # Get the best validation loss achieved by this trial\n",
    "    val_loss = trial.metrics.get_best_value('val_loss')\n",
    "    \n",
    "    rows.append({\n",
    "        'trial_id': trial.trial_id,\n",
    "        'val_loss': val_loss,\n",
    "        'num_layers': num_layers,\n",
    "        'units_layer_0': rec_units[0],\n",
    "        'units_layer_1': rec_units[1],\n",
    "        'units_layer_2': rec_units[2],\n",
    "        'units_layer_3': rec_units[3],\n",
    "    })\n",
    "\n",
    "# Build and display a DataFrame\n",
    "df_top10 = pd.DataFrame(rows).sort_values('val_loss').reset_index(drop=True)\n",
    "df_top10\n",
    "\n",
    "\n",
    "\n",
    "# 1) Grab the best HP from stage 1\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# 2) Update GLOBAL_CONFIG in memory\n",
    "GLOBAL_CONFIG[\"best_architecture\"] = {\n",
    "    \"num_layers\": best_hp.get(\"num_layers\"),\n",
    "    \"recurrent_units\": [\n",
    "        best_hp.get(f\"recurrent_units_{i}\") \n",
    "        for i in range(best_hp.get(\"num_layers\"))\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 3) (Optional) Persist to disk as config.json\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(GLOBAL_CONFIG, f, indent=2)\n",
    "\n",
    "print(\"✅ GLOBAL_CONFIG updated:\", GLOBAL_CONFIG[\"best_architecture\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units_layer_0</th>\n",
       "      <th>units_layer_1</th>\n",
       "      <th>units_layer_2</th>\n",
       "      <th>units_layer_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>052</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>125</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>079</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>055</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>040</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_id  val_loss  num_layers  units_layer_0  units_layer_1  units_layer_2  \\\n",
       "0      119  0.004202           2             32            8.0            NaN   \n",
       "1      158  0.004238           1             32            NaN            NaN   \n",
       "2      157  0.004388           2             64           16.0            NaN   \n",
       "3      149  0.004633           2             64           16.0            NaN   \n",
       "4      052  0.004742           2             16            8.0            NaN   \n",
       "5      125  0.004798           2             64           64.0            NaN   \n",
       "6      079  0.004833           2            128          128.0            NaN   \n",
       "7      115  0.004844           4             64            8.0           32.0   \n",
       "8      055  0.005066           2            128           64.0            NaN   \n",
       "9      040  0.005203           3             64           64.0           32.0   \n",
       "\n",
       "   units_layer_3  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "5            NaN  \n",
       "6            NaN  \n",
       "7           16.0  \n",
       "8            NaN  \n",
       "9            NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 tuning - regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 01m 38s]\n",
      "val_loss: 0.016901787370443344\n",
      "\n",
      "Best val_loss So Far: 0.005584084894508123\n",
      "Total elapsed time: 21h 09m 57s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    rnn.build_regularization_model,  # Your stage 2 model-building function\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=200,\n",
    "    directory=\"rnn_tuning_stage2\",  # New directory for stage 2\n",
    "    project_name=\"rnn_reg_tuning\",\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "# ✅ Enable TensorBoard Logging\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/random_search_2\", histogram_freq=1)\n",
    "\n",
    "# ✅ Start tuning with random search\n",
    "tuner.search(\n",
    "    X_train, expand(y_train),\n",
    "    epochs = 50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>dropout_0</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>recurrent_dropout_0</th>\n",
       "      <th>recurrent_dropout_1</th>\n",
       "      <th>batch_norm_0</th>\n",
       "      <th>batch_norm_1</th>\n",
       "      <th>layer_norm_0</th>\n",
       "      <th>layer_norm_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>017</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>090</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>074</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>064</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>030</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>067</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_id  val_loss  dropout_0  dropout_1  recurrent_dropout_0  \\\n",
       "0      160  0.005584        0.0        0.0                  0.1   \n",
       "1      017  0.006435        0.0        0.0                  0.0   \n",
       "2      090  0.006565        0.0        0.0                  0.0   \n",
       "3      074  0.006785        0.0        0.0                  0.0   \n",
       "4      064  0.006957        0.0        0.1                  0.0   \n",
       "5      190  0.007147        0.0        0.0                  0.2   \n",
       "6      132  0.007388        0.0        0.1                  0.1   \n",
       "7      180  0.007700        0.0        0.0                  0.2   \n",
       "8      030  0.007811        0.0        0.1                  0.2   \n",
       "9      067  0.008274        0.0        0.1                  0.0   \n",
       "\n",
       "   recurrent_dropout_1  batch_norm_0  batch_norm_1  layer_norm_0  layer_norm_1  \n",
       "0                  0.2         False         False          True         False  \n",
       "1                  0.1         False         False          True         False  \n",
       "2                  0.0         False         False          True         False  \n",
       "3                  0.2          True         False         False         False  \n",
       "4                  0.1         False         False          True         False  \n",
       "5                  0.0         False         False          True          True  \n",
       "6                  0.1          True         False         False         False  \n",
       "7                  0.0         False         False         False         False  \n",
       "8                  0.2         False         False          True         False  \n",
       "9                  0.0          True         False          True         False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 trials\n",
    "best_trials = tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "rows = []\n",
    "for trial in best_trials:\n",
    "    hp = trial.hyperparameters\n",
    "    num_layers = GLOBAL_CONFIG[\"best_architecture\"][\"num_layers\"]\n",
    "    # pull out each layer’s regularization HPs\n",
    "    dr   = [ hp.get(f\"dropout_{i}\")           for i in range(num_layers) ]\n",
    "    rdr  = [ hp.get(f\"recurrent_dropout_{i}\") for i in range(num_layers) ]\n",
    "    bn   = [ hp.get(f\"batch_norm_{i}\")        for i in range(num_layers) ]\n",
    "    ln   = [ hp.get(f\"layer_norm_{i}\")        for i in range(num_layers) ]\n",
    "    val_loss = trial.metrics.get_best_value(\"val_loss\")\n",
    "\n",
    "    rows.append({\n",
    "      \"trial_id\":       trial.trial_id,\n",
    "      \"val_loss\":       val_loss,\n",
    "      **{f\"dropout_{i}\":           dr[i]  for i in range(num_layers)},\n",
    "      **{f\"recurrent_dropout_{i}\": rdr[i] for i in range(num_layers)},\n",
    "      **{f\"batch_norm_{i}\":        bn[i]  for i in range(num_layers)},\n",
    "      **{f\"layer_norm_{i}\":        ln[i]  for i in range(num_layers)},\n",
    "    })\n",
    "\n",
    "df_reg_top10 = pd.DataFrame(rows).sort_values(\"val_loss\").reset_index(drop=True)\n",
    "df_reg_top10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GLOBAL_CONFIG updated: {'num_layers': 2, 'recurrent_units': [32, 8]}\n"
     ]
    }
   ],
   "source": [
    "# Run this right after tuner.search(...)\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# Build your new regularization_defaults entry\n",
    "num_layers = GLOBAL_CONFIG[\"best_architecture\"][\"num_layers\"]\n",
    "GLOBAL_CONFIG[\"regularization_defaults\"] = {\n",
    "  \"dropout\": [best_hp.get(f\"dropout_{i}\") for i in range(num_layers)],\n",
    "  \"recurrent_dropout\": [best_hp.get(f\"recurrent_dropout_{i}\") for i in range(num_layers)],\n",
    "  \"batch_norm\": [best_hp.get(f\"batch_norm_{i}\") for i in range(num_layers)],\n",
    "  \"layer_norm\": [ best_hp.get(f\"layer_norm_{i}\") for i in range(num_layers) ]\n",
    "}\n",
    "# 3) (Optional) Persist to disk as config.json\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(GLOBAL_CONFIG, f, indent=2)\n",
    "print(\"✅ GLOBAL_CONFIG updated:\", GLOBAL_CONFIG[\"best_architecture\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 tuning - Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 Complete [00h 01m 00s]\n",
      "val_loss: 0.013994532637298107\n",
      "\n",
      "Best val_loss So Far: 0.0030403342097997665\n",
      "Total elapsed time: 05h 31m 27s\n",
      "\n",
      "Search: Running Trial #148\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.00088066        |0.0050448         |lr\n",
      "none              |exponential       |scheduler\n",
      "adam              |nadam             |optimizer\n",
      "15708             |4862              |decay_steps_cosine\n",
      "13090             |8602              |decay_steps_exponential\n",
      "0.95              |0.83              |decay_rate_exp\n",
      "\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    rnn.build_optimization_model,  # Stage 3 model function\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=200,\n",
    "    directory=\"rnn_tuning_stage3\",\n",
    "    project_name=\"rnn_opt_tuning\",\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/opt_tuning\", histogram_freq=1)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, expand(y_train),\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GLOBAL_CONFIG.optimization_defaults = {'lr': 0.003425317024450299, 'scheduler': 'none', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# 2) Build the new optimization_defaults dict directly from the HPs\n",
    "opt_cfg = {\n",
    "    \"lr\": float(best_hp.get(\"lr\")),\n",
    "    \"scheduler\": best_hp.get(\"scheduler\"),\n",
    "    \"optimizer\": best_hp.get(\"optimizer\"),\n",
    "}\n",
    "\n",
    "# 3) Depending on the scheduler choice, pull the right decay values\n",
    "if opt_cfg[\"scheduler\"] == \"cosine\":\n",
    "    opt_cfg[\"decay_steps\"] = int(best_hp.get(\"decay_steps_cosine\"))\n",
    "elif opt_cfg[\"scheduler\"] == \"exponential\":\n",
    "    opt_cfg[\"decay_steps\"] = int(best_hp.get(\"decay_steps_exp\"))\n",
    "    opt_cfg[\"decay_rate\"]  = float(best_hp.get(\"decay_rate_exp\"))\n",
    "# if scheduler==\"none\", we leave it at just lr/optimizer\n",
    "\n",
    "# 4) Update in‐memory GLOBAL_CONFIG and persist to disk\n",
    "GLOBAL_CONFIG[\"optimization_defaults\"] = opt_cfg\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(GLOBAL_CONFIG, f, indent=2)\n",
    "\n",
    "print(\"✅ GLOBAL_CONFIG.optimization_defaults =\", GLOBAL_CONFIG[\"optimization_defaults\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trial_id  val_loss        lr    scheduler  decay_steps_cosine  \\\n",
      "0      137  0.002438  0.007238         none                 NaN   \n",
      "1      027  0.002681  0.006417  exponential                 NaN   \n",
      "2      069  0.002985  0.004824       cosine             13838.0   \n",
      "3      146  0.003036  0.004763  exponential                 NaN   \n",
      "4      066  0.003307  0.006158         none                 NaN   \n",
      "5      094  0.003428  0.002808         none                 NaN   \n",
      "6      095  0.003614  0.009948         none                 NaN   \n",
      "7      184  0.003810  0.008387       cosine             12716.0   \n",
      "8      096  0.003873  0.006694       cosine             11220.0   \n",
      "9      170  0.003934  0.005031  exponential                 NaN   \n",
      "\n",
      "  decay_steps_exponential decay_rate_exponential optimizer  \n",
      "0                    None                   None      adam  \n",
      "1                    None                   None     nadam  \n",
      "2                    None                   None      adam  \n",
      "3                    None                   None     nadam  \n",
      "4                    None                   None      adam  \n",
      "5                    None                   None      adam  \n",
      "6                    None                   None      adam  \n",
      "7                    None                   None     nadam  \n",
      "8                    None                   None      adam  \n",
      "9                    None                   None     nadam  \n"
     ]
    }
   ],
   "source": [
    "# 1) Grab the top-10 (or fewer if you only ran 5) trials\n",
    "best_trials = tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "rows = []\n",
    "for trial in best_trials:\n",
    "    hp       = trial.hyperparameters\n",
    "    val_loss = trial.metrics.get_best_value(\"val_loss\")\n",
    "\n",
    "    # these are the tuned HPs in build_optimization_model:\n",
    "    lr          = hp.get(\"lr\")\n",
    "    sched       = hp.get(\"scheduler\")\n",
    "    # conditionally pull out the scheduler params\n",
    "    decay_cos   = hp.get(\"decay_steps_cosine\") if sched == \"cosine\"      else None\n",
    "    # decay_exp   = hp.get(\"decay_steps_exp\")   if sched == \"exponential\" else None\n",
    "    # rate_exp    = hp.get(\"decay_rate_exp\")    if sched == \"exponential\" else None\n",
    "    optimizer   = hp.get(\"optimizer\")\n",
    "\n",
    "    rows.append({\n",
    "        \"trial_id\":            trial.trial_id,\n",
    "        \"val_loss\":            val_loss,\n",
    "        \"lr\":                  lr,\n",
    "        \"scheduler\":           sched,\n",
    "        \"decay_steps_cosine\":  decay_cos,\n",
    "        \"decay_steps_exponential\": decay_exp,\n",
    "        \"decay_rate_exponential\":  rate_exp,\n",
    "        \"optimizer\":           optimizer,\n",
    "    })\n",
    "\n",
    "# 2) Build & sort your DataFrame\n",
    "df_opt_top10 = (\n",
    "    pd.DataFrame(rows)\n",
    "      .sort_values(\"val_loss\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 3) Inspect\n",
    "print(df_opt_top10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4 Tuning - Other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 17s]\n",
      "val_loss: 0.007096894085407257\n",
      "\n",
      "Best val_loss So Far: 0.0054009887389838696\n",
      "Total elapsed time: 00h 04m 59s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.GridSearch(\n",
    "    rnn.build_stage4_model,  # Stage 4 model function\n",
    "    objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "    directory=\"rnn_tuning_stage4\",  # New directory for stage 4\n",
    "    project_name=\"rnn_extra_tuning\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs/stage4\", histogram_freq=1)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, expand(y_train),\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        tensorboard_callback\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'sequence_length': 25}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GLOBAL_CONFIG.sequence_length.use_length set to 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) After your tuner.search(...)\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# 2) Pull out the winning window‐length choice\n",
    "best_seq = int(best_hp.get(\"sequence_length\"))\n",
    "\n",
    "# 3) Update your in‐memory config\n",
    "GLOBAL_CONFIG[\"sequence_length\"][\"use_length\"] = best_seq\n",
    "\n",
    "# 4) Persist it to disk\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(GLOBAL_CONFIG, f, indent=2)\n",
    "\n",
    "print(f\"✅ GLOBAL_CONFIG.sequence_length.use_length set to {best_seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004</td>\n",
       "      <td>25</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_id  sequence_length  val_loss\n",
       "0     0004               25  0.002344\n",
       "1     0003               20  0.002505\n",
       "2     0001               10  0.003483\n",
       "3     0000                5  0.003730\n",
       "4     0002               15  0.003759"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all trials\n",
    "rows = []\n",
    "for trial in tuner.oracle.trials.values():\n",
    "    hp       = trial.hyperparameters\n",
    "    seq_len  = hp.get(\"sequence_length\")\n",
    "    # get the best val_loss this trial ever saw\n",
    "    val_loss = trial.metrics.get_best_value(\"val_loss\")\n",
    "    rows.append({\n",
    "        \"trial_id\":        trial.trial_id,\n",
    "        \"sequence_length\": seq_len,\n",
    "        \"val_loss\":        val_loss\n",
    "    })\n",
    "\n",
    "# build a DataFrame and sort by loss\n",
    "df_stage4 = (\n",
    "    pd.DataFrame(rows)\n",
    "      .sort_values(\"val_loss\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_stage4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - angle_output_loss: 0.1649 - loc_output_loss: 0.0126 - loss: 0.1776 - val_angle_output_loss: 0.0146 - val_loc_output_loss: 9.6370e-04 - val_loss: 0.0148\n",
      "Epoch 2/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0170 - loc_output_loss: 7.1653e-04 - loss: 0.0177 - val_angle_output_loss: 0.0095 - val_loc_output_loss: 8.7927e-04 - val_loss: 0.0096\n",
      "Epoch 3/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0127 - loc_output_loss: 6.4449e-04 - loss: 0.0133 - val_angle_output_loss: 0.0073 - val_loc_output_loss: 8.2591e-04 - val_loss: 0.0077\n",
      "Epoch 4/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - angle_output_loss: 0.0089 - loc_output_loss: 5.3365e-04 - loss: 0.0094 - val_angle_output_loss: 0.0049 - val_loc_output_loss: 8.3332e-04 - val_loss: 0.0054\n",
      "Epoch 5/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - angle_output_loss: 0.0072 - loc_output_loss: 4.6188e-04 - loss: 0.0077 - val_angle_output_loss: 0.0046 - val_loc_output_loss: 9.4387e-04 - val_loss: 0.0052\n",
      "Epoch 6/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - angle_output_loss: 0.0055 - loc_output_loss: 4.0359e-04 - loss: 0.0059 - val_angle_output_loss: 0.0048 - val_loc_output_loss: 9.2354e-04 - val_loss: 0.0054\n",
      "Epoch 7/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0051 - loc_output_loss: 4.2214e-04 - loss: 0.0055 - val_angle_output_loss: 0.0041 - val_loc_output_loss: 8.9725e-04 - val_loss: 0.0047\n",
      "Epoch 8/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0041 - loc_output_loss: 3.4544e-04 - loss: 0.0045 - val_angle_output_loss: 0.0032 - val_loc_output_loss: 7.5027e-04 - val_loss: 0.0037\n",
      "Epoch 9/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0035 - loc_output_loss: 3.4231e-04 - loss: 0.0039 - val_angle_output_loss: 0.0036 - val_loc_output_loss: 8.3469e-04 - val_loss: 0.0042\n",
      "Epoch 10/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0032 - loc_output_loss: 3.0009e-04 - loss: 0.0035 - val_angle_output_loss: 0.0027 - val_loc_output_loss: 7.2750e-04 - val_loss: 0.0032\n",
      "Epoch 11/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0027 - loc_output_loss: 2.8523e-04 - loss: 0.0030 - val_angle_output_loss: 0.0023 - val_loc_output_loss: 7.1072e-04 - val_loss: 0.0028\n",
      "Epoch 12/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0024 - loc_output_loss: 2.7209e-04 - loss: 0.0026 - val_angle_output_loss: 0.0021 - val_loc_output_loss: 8.1985e-04 - val_loss: 0.0026\n",
      "Epoch 13/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0021 - loc_output_loss: 2.4589e-04 - loss: 0.0023 - val_angle_output_loss: 0.0022 - val_loc_output_loss: 8.0888e-04 - val_loss: 0.0028\n",
      "Epoch 14/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0019 - loc_output_loss: 2.4562e-04 - loss: 0.0022 - val_angle_output_loss: 0.0020 - val_loc_output_loss: 8.8233e-04 - val_loss: 0.0026\n",
      "Epoch 15/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 0.0017 - loc_output_loss: 2.1764e-04 - loss: 0.0019 - val_angle_output_loss: 0.0017 - val_loc_output_loss: 7.9123e-04 - val_loss: 0.0022\n",
      "Epoch 16/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0015 - loc_output_loss: 2.1381e-04 - loss: 0.0017 - val_angle_output_loss: 0.0018 - val_loc_output_loss: 7.7767e-04 - val_loss: 0.0023\n",
      "Epoch 17/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0014 - loc_output_loss: 1.9474e-04 - loss: 0.0016 - val_angle_output_loss: 0.0016 - val_loc_output_loss: 7.8536e-04 - val_loss: 0.0021\n",
      "Epoch 18/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0014 - loc_output_loss: 1.9253e-04 - loss: 0.0016 - val_angle_output_loss: 0.0017 - val_loc_output_loss: 8.7109e-04 - val_loss: 0.0022\n",
      "Epoch 19/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0012 - loc_output_loss: 1.7683e-04 - loss: 0.0014 - val_angle_output_loss: 0.0014 - val_loc_output_loss: 7.4284e-04 - val_loss: 0.0019\n",
      "Epoch 20/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 0.0011 - loc_output_loss: 1.7293e-04 - loss: 0.0013 - val_angle_output_loss: 0.0014 - val_loc_output_loss: 8.2108e-04 - val_loss: 0.0019\n",
      "Epoch 21/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 9.5135e-04 - loc_output_loss: 1.5593e-04 - loss: 0.0011 - val_angle_output_loss: 0.0019 - val_loc_output_loss: 7.7685e-04 - val_loss: 0.0024\n",
      "Epoch 22/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - angle_output_loss: 9.3280e-04 - loc_output_loss: 1.5193e-04 - loss: 0.0011 - val_angle_output_loss: 0.0013 - val_loc_output_loss: 7.5389e-04 - val_loss: 0.0018\n",
      "Epoch 23/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 8.2293e-04 - loc_output_loss: 1.4212e-04 - loss: 9.6505e-04 - val_angle_output_loss: 0.0012 - val_loc_output_loss: 8.2786e-04 - val_loss: 0.0017\n",
      "Epoch 24/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 7.7682e-04 - loc_output_loss: 1.3443e-04 - loss: 9.1125e-04 - val_angle_output_loss: 0.0013 - val_loc_output_loss: 7.9523e-04 - val_loss: 0.0018\n",
      "Epoch 25/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 7.1016e-04 - loc_output_loss: 1.3166e-04 - loss: 8.4181e-04 - val_angle_output_loss: 0.0013 - val_loc_output_loss: 7.4018e-04 - val_loss: 0.0018\n",
      "Epoch 26/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 6.5744e-04 - loc_output_loss: 1.2181e-04 - loss: 7.7925e-04 - val_angle_output_loss: 0.0012 - val_loc_output_loss: 8.2128e-04 - val_loss: 0.0018\n",
      "Epoch 27/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 6.1127e-04 - loc_output_loss: 1.1549e-04 - loss: 7.2675e-04 - val_angle_output_loss: 0.0013 - val_loc_output_loss: 7.3523e-04 - val_loss: 0.0018\n",
      "Epoch 28/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 5.9779e-04 - loc_output_loss: 1.1195e-04 - loss: 7.0974e-04 - val_angle_output_loss: 0.0012 - val_loc_output_loss: 7.7523e-04 - val_loss: 0.0017\n",
      "Epoch 29/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 5.3603e-04 - loc_output_loss: 9.9267e-05 - loss: 6.3530e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 7.9422e-04 - val_loss: 0.0016\n",
      "Epoch 30/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 5.4725e-04 - loc_output_loss: 1.0080e-04 - loss: 6.4806e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 7.9274e-04 - val_loss: 0.0016\n",
      "Epoch 31/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 4.6314e-04 - loc_output_loss: 9.2192e-05 - loss: 5.5534e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 8.1999e-04 - val_loss: 0.0016\n",
      "Epoch 32/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 4.4147e-04 - loc_output_loss: 9.0492e-05 - loss: 5.3196e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 7.6387e-04 - val_loss: 0.0016\n",
      "Epoch 33/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 4.1959e-04 - loc_output_loss: 8.6576e-05 - loss: 5.0617e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 8.1126e-04 - val_loss: 0.0016\n",
      "Epoch 34/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 3.8451e-04 - loc_output_loss: 8.7171e-05 - loss: 4.7168e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 7.8102e-04 - val_loss: 0.0016\n",
      "Epoch 35/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 3.6409e-04 - loc_output_loss: 7.9203e-05 - loss: 4.4329e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 8.6827e-04 - val_loss: 0.0017\n",
      "Epoch 36/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 3.4339e-04 - loc_output_loss: 7.5287e-05 - loss: 4.1868e-04 - val_angle_output_loss: 0.0011 - val_loc_output_loss: 7.5348e-04 - val_loss: 0.0015\n",
      "Epoch 37/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 3.2664e-04 - loc_output_loss: 7.1965e-05 - loss: 3.9860e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 8.1362e-04 - val_loss: 0.0015\n",
      "Epoch 38/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 3.1233e-04 - loc_output_loss: 7.2119e-05 - loss: 3.8444e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 7.7813e-04 - val_loss: 0.0015\n",
      "Epoch 39/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.9557e-04 - loc_output_loss: 6.5790e-05 - loss: 3.6136e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 8.1222e-04 - val_loss: 0.0015\n",
      "Epoch 40/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.7910e-04 - loc_output_loss: 6.3755e-05 - loss: 3.4285e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 7.7281e-04 - val_loss: 0.0015\n",
      "Epoch 41/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.6629e-04 - loc_output_loss: 6.5618e-05 - loss: 3.3191e-04 - val_angle_output_loss: 9.4296e-04 - val_loc_output_loss: 8.0941e-04 - val_loss: 0.0014\n",
      "Epoch 42/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.5519e-04 - loc_output_loss: 6.2611e-05 - loss: 3.1780e-04 - val_angle_output_loss: 9.6838e-04 - val_loc_output_loss: 7.9387e-04 - val_loss: 0.0015\n",
      "Epoch 43/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - angle_output_loss: 2.3233e-04 - loc_output_loss: 5.8515e-05 - loss: 2.9084e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 7.8536e-04 - val_loss: 0.0015\n",
      "Epoch 44/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.3196e-04 - loc_output_loss: 5.5239e-05 - loss: 2.8720e-04 - val_angle_output_loss: 9.8580e-04 - val_loc_output_loss: 7.6513e-04 - val_loss: 0.0015\n",
      "Epoch 45/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.1910e-04 - loc_output_loss: 5.3610e-05 - loss: 2.7271e-04 - val_angle_output_loss: 9.5488e-04 - val_loc_output_loss: 8.2148e-04 - val_loss: 0.0015\n",
      "Epoch 46/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 2.1211e-04 - loc_output_loss: 5.2918e-05 - loss: 2.6502e-04 - val_angle_output_loss: 9.9078e-04 - val_loc_output_loss: 7.8966e-04 - val_loss: 0.0015\n",
      "Epoch 47/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.9582e-04 - loc_output_loss: 5.1061e-05 - loss: 2.4688e-04 - val_angle_output_loss: 9.8653e-04 - val_loc_output_loss: 8.5594e-04 - val_loss: 0.0015\n",
      "Epoch 48/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.8709e-04 - loc_output_loss: 5.0497e-05 - loss: 2.3758e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 8.1387e-04 - val_loss: 0.0015\n",
      "Epoch 49/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.8129e-04 - loc_output_loss: 4.8124e-05 - loss: 2.2941e-04 - val_angle_output_loss: 0.0010 - val_loc_output_loss: 8.0014e-04 - val_loss: 0.0015\n",
      "Epoch 50/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.7891e-04 - loc_output_loss: 4.6112e-05 - loss: 2.2502e-04 - val_angle_output_loss: 9.8765e-04 - val_loc_output_loss: 8.1973e-04 - val_loss: 0.0015\n",
      "Epoch 51/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.6435e-04 - loc_output_loss: 4.6289e-05 - loss: 2.1064e-04 - val_angle_output_loss: 9.6433e-04 - val_loc_output_loss: 7.9053e-04 - val_loss: 0.0015\n",
      "Epoch 52/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.6061e-04 - loc_output_loss: 4.4689e-05 - loss: 2.0530e-04 - val_angle_output_loss: 9.4309e-04 - val_loc_output_loss: 8.1741e-04 - val_loss: 0.0014\n",
      "Epoch 53/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.5696e-04 - loc_output_loss: 4.4486e-05 - loss: 2.0145e-04 - val_angle_output_loss: 9.3764e-04 - val_loc_output_loss: 7.7728e-04 - val_loss: 0.0014\n",
      "Epoch 54/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.5361e-04 - loc_output_loss: 4.2266e-05 - loss: 1.9588e-04 - val_angle_output_loss: 9.7393e-04 - val_loc_output_loss: 7.8029e-04 - val_loss: 0.0014\n",
      "Epoch 55/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.4521e-04 - loc_output_loss: 4.1581e-05 - loss: 1.8679e-04 - val_angle_output_loss: 9.6419e-04 - val_loc_output_loss: 7.9932e-04 - val_loss: 0.0015\n",
      "Epoch 56/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.4218e-04 - loc_output_loss: 4.0139e-05 - loss: 1.8232e-04 - val_angle_output_loss: 9.8461e-04 - val_loc_output_loss: 7.9671e-04 - val_loss: 0.0015\n",
      "Epoch 57/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.3623e-04 - loc_output_loss: 3.8164e-05 - loss: 1.7439e-04 - val_angle_output_loss: 9.6601e-04 - val_loc_output_loss: 8.1668e-04 - val_loss: 0.0015\n",
      "Epoch 58/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.3575e-04 - loc_output_loss: 3.9423e-05 - loss: 1.7518e-04 - val_angle_output_loss: 9.5958e-04 - val_loc_output_loss: 8.2539e-04 - val_loss: 0.0015\n",
      "Epoch 59/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.3090e-04 - loc_output_loss: 3.8290e-05 - loss: 1.6919e-04 - val_angle_output_loss: 9.4714e-04 - val_loc_output_loss: 8.2545e-04 - val_loss: 0.0015\n",
      "Epoch 60/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.2574e-04 - loc_output_loss: 3.6384e-05 - loss: 1.6212e-04 - val_angle_output_loss: 9.6121e-04 - val_loc_output_loss: 8.1315e-04 - val_loss: 0.0015\n",
      "Epoch 61/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.2685e-04 - loc_output_loss: 3.7571e-05 - loss: 1.6442e-04 - val_angle_output_loss: 9.5238e-04 - val_loc_output_loss: 7.9223e-04 - val_loss: 0.0014\n",
      "Epoch 62/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.2533e-04 - loc_output_loss: 3.5826e-05 - loss: 1.6115e-04 - val_angle_output_loss: 9.9045e-04 - val_loc_output_loss: 8.3294e-04 - val_loss: 0.0015\n",
      "Epoch 63/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.1785e-04 - loc_output_loss: 3.5762e-05 - loss: 1.5361e-04 - val_angle_output_loss: 9.5586e-04 - val_loc_output_loss: 8.1884e-04 - val_loss: 0.0015\n",
      "Epoch 64/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.1660e-04 - loc_output_loss: 3.5143e-05 - loss: 1.5174e-04 - val_angle_output_loss: 9.4641e-04 - val_loc_output_loss: 8.0966e-04 - val_loss: 0.0014\n",
      "Epoch 65/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.1236e-04 - loc_output_loss: 3.4144e-05 - loss: 1.4651e-04 - val_angle_output_loss: 9.8386e-04 - val_loc_output_loss: 8.3640e-04 - val_loss: 0.0015\n",
      "Epoch 66/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.0898e-04 - loc_output_loss: 3.4415e-05 - loss: 1.4340e-04 - val_angle_output_loss: 9.4278e-04 - val_loc_output_loss: 7.9832e-04 - val_loss: 0.0014\n",
      "Epoch 67/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.0994e-04 - loc_output_loss: 3.4002e-05 - loss: 1.4395e-04 - val_angle_output_loss: 9.3869e-04 - val_loc_output_loss: 8.1384e-04 - val_loss: 0.0014\n",
      "Epoch 68/500\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - angle_output_loss: 1.0561e-04 - loc_output_loss: 3.3654e-05 - loss: 1.3926e-04 - val_angle_output_loss: 9.5460e-04 - val_loc_output_loss: 8.2186e-04 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "best_model = rnn.build_final_model()\n",
    "\n",
    "\n",
    "history = best_model.fit(\n",
    "    x = X_train[:,-25:,:], \n",
    "    y = expand(y_train),\n",
    "    validation_data=(X_valid[:,-25:,:], expand(y_valid)),\n",
    "    epochs=500, \n",
    "    batch_size=32, \n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(MODELS_DIR / 'navigation_neural_nets/rnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnn.build_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36131644  0.42512816 -0.02062177 -0.10213882  0.02400358  0.02550364\n",
      "   0.42134658  0.5544123 ]]\n",
      "[[ 0.36131644  0.42512816 -0.02062177 -0.10213882  0.02400358  0.02550364\n",
      "   0.42134658  0.5544123 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyrelglass/miniforge3/envs/robot-vlp/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 22 variables whereas the saved optimizer has 1 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "best_model = rnn.build_final_model()\n",
    "best_model.save(MODELS_DIR / 'navigation_neural_nets/rnn.keras')\n",
    "\n",
    "print(best_model.get_layer('feature_norm').mean.numpy())\n",
    "\n",
    "rnn_mod = load_model(MODELS_DIR / 'navigation_neural_nets/rnn.keras') \n",
    "print(rnn_mod.get_layer('feature_norm').mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_layer('feature_norm').mean.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_layer('feature_norm').variance.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_norm        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ feature_norm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ lstm_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ loc_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ angle_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ feature_norm        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │         \u001b[38;5;34m17\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_0 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m18,688\u001b[0m │ feature_norm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m33,024\u001b[0m │ lstm_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ loc_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m130\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ angle_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m130\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,935</span> (609.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m155,935\u001b[0m (609.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,972</span> (203.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,972\u001b[0m (203.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,946</span> (406.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m103,946\u001b[0m (406.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vec_to_ang' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pre_loc, pre_ang \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m25\u001b[39m:,:])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# rnn_loc_errs = calc_loc_err(pre_loc, y_test[:,:2])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m rnn_ang_errs \u001b[38;5;241m=\u001b[39m \u001b[43mvec_to_ang\u001b[49m(pre_ang) \u001b[38;5;241m-\u001b[39m y_test[:,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m rnn_ang_errs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([normalize_angle_deg(ang) \u001b[38;5;28;01mfor\u001b[39;00m ang \u001b[38;5;129;01min\u001b[39;00m rnn_ang_errs])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvlp pos errs:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvlp_loc_errs\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vec_to_ang' is not defined"
     ]
    }
   ],
   "source": [
    "pre_loc, pre_ang = best_model.predict(X_test[:,-25:,:])\n",
    "# rnn_loc_errs = calc_loc_err(pre_loc, y_test[:,:2])\n",
    "rnn_ang_errs = vec_to_ang(pre_ang) - y_test[:,2]\n",
    "rnn_ang_errs = np.array([normalize_angle_deg(ang) for ang in rnn_ang_errs])\n",
    "\n",
    "print(f\"vlp pos errs:{vlp_loc_errs.mean()}\")\n",
    "# print(f\"RNN pos errs:{rnn_loc_errs.mean()}\")\n",
    "print(f\"VLP heading errs:{np.abs(vlp_ang_errs).mean()}\")\n",
    "print(f\"RNN heading errs:{np.abs(rnn_ang_errs).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(MODELS_DIR / 'navigation_neural_nets/rnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pre_loc[:15,0],pre_loc[:15,1], label = 'predictions', marker = '.')\n",
    "plt.plot(y_train[:15,0], y_train[:15,1], label = 'real', marker = '.')\n",
    "# plt.plot(df['vlp_x_hist'], df['vlp_y_hist'])\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robot_vlp.modeling.mlp as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp.build_default_mlp()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x = X_train_scaled[:,-1,:], \n",
    "    y = expand(y_train),\n",
    "    validation_data = (X_valid_scaled[:,-1,:],  expand(y_valid)),\n",
    "    epochs=300, \n",
    "    batch_size=32, \n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)] )\n",
    "\n",
    "\n",
    "pre_loc, pre_ang = model.predict(X_test_scaled[:,-1,:])\n",
    "MLP_loc_errs = calc_loc_err(pre_loc, y_test[:,:2])\n",
    "\n",
    "MLP_ang_errs = vec_to_ang(pre_ang) - y_test[:,2]\n",
    "MLP_ang_errs = np.array([normalize_angle_deg(ang) for ang in MLP_ang_errs])\n",
    "\n",
    "\n",
    "vlp_ang_errs = y_test[:,2] -  X_test[:,-1,2]\n",
    "vlp_ang_errs = np.array([normalize_angle_deg(ang) for ang in vlp_ang_errs])\n",
    "\n",
    "\n",
    "vlp_loc_errs = calc_loc_err(X_test[:,-1,:2], y_test[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"vlp pos errs:{vlp_loc_errs.mean()}\")\n",
    "print(f\"MLP pos errs:{MLP_loc_errs.mean()}\")\n",
    "\n",
    "\n",
    "print(f\"VLP heading errs:{np.abs(vlp_ang_errs).mean()}\")\n",
    "print(f\"MLP heading errs:{np.abs(MLP_ang_errs).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot-vlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
